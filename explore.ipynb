{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6756684b",
   "metadata": {},
   "source": [
    "# Deepfake Image Classification with PyTorch\n",
    "\n",
    "This notebook demonstrates a full workflow for classifying deepfake images using a convolutional neural network (CNN) in PyTorch. The steps include data exploration, preprocessing, model building, training, and evaluation, with visualizations and clear explanations throughout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891ab854",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbc61f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd429b",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize a Sample Image\n",
    "Display a sample image from the dataset to verify image loading and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Display a sample image to verify loading\n",
    "def show_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_image(\"FF++/Fake/000_003/001_0.tiff\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5de5ff",
   "metadata": {},
   "source": [
    "### Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def explore_dataset(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    for category in root.iterdir():\n",
    "        print(f\"[{category.name}]\")\n",
    "        for person_folder in category.iterdir():\n",
    "            print(f\"  - {person_folder.name}: {len(list(person_folder.glob('*.tiff')))} images\")\n",
    "explore_dataset(\"FF++\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f4396",
   "metadata": {},
   "source": [
    "### Prepare the Dataset List\n",
    "Create a list of image file paths and their corresponding labels for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ddd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "image_label_list = []\n",
    "\n",
    "def prepare_dataset_list(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    for label_str, label_num in [('Real', 0), ('Fake', 1)]:\n",
    "        label_path = root / label_str\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "        for person_folder in label_path.iterdir():\n",
    "            if person_folder.is_dir():\n",
    "                for image_path in person_folder.glob('*.tiff'):\n",
    "                    image_label_list.append((str(image_path), label_num))\n",
    "    return image_label_list\n",
    "dataset_list = prepare_dataset_list(\"FF++\")\n",
    "print(\"Sampled Dataset Size:\", len(dataset_list))\n",
    "print(\"Sample:\", dataset_list[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0682f06",
   "metadata": {},
   "source": [
    "note : we could've used the `load_dataset` from `datasets` but each dataset would be {'image': {'path': '/path/to/image.jpg', 'bytes': None}, 'label': 1} which is very long "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc39491",
   "metadata": {},
   "source": [
    "### Print Folder Names and Image Counts\n",
    "\n",
    "This section demonstrates how to display the names of the folders and the number of images sampled from each folder to verify data sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5669470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_folder_image_counts(root_dir):\n",
    "    sumImages = 0\n",
    "    root = Path(root_dir)\n",
    "    for label_str, label_num in [('real', 0), ('fake', 1)]:\n",
    "        label_path = root / label_str\n",
    "        if not label_path.exists():\n",
    "            continue\n",
    "        print(f\"Category: {label_str}\")\n",
    "        dirs = sorted(label_path.iterdir())\n",
    "        for person_folder in dirs:\n",
    "            if person_folder.is_dir():\n",
    "                image_count = len(list(person_folder.glob('*.tiff')))\n",
    "                sumImages+=image_count\n",
    "                print(f\"Folder: {person_folder.name}, Images Taken: {image_count}\")\n",
    "    print(f'the total images in the {root_dir} directory is : {sumImages}')\n",
    "print_folder_image_counts(\"FF++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7803b2",
   "metadata": {},
   "source": [
    "### Implement a Basic Data Loader\n",
    "Convert image files to tensors and prepare them for model input using PyTorch utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae424031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from PIL import Image\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # Step 1: Define a transform (resize, tensor, normalize)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "# ])\n",
    "\n",
    "# # Step 2: Prepare your dataset list\n",
    "# def prepare_dataset(data_list, transform):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "\n",
    "#     for path, label in data_list:\n",
    "#         print(f\"Loading: {path}\")  # Debug print\n",
    "#         img = Image.open(path).convert('RGB')\n",
    "#         img = transform(img)\n",
    "#         print(f\"Transformed shape: {img.shape}, dtype: {img.dtype}\")  # Debug info\n",
    "#         images.append(img)\n",
    "#         labels.append(label)\n",
    "\n",
    "#     return torch.stack(images), torch.tensor(labels)\n",
    "\n",
    "# # Step 3: Example usage\n",
    "# image_tensors, label_tensors = prepare_dataset(dataset_list, transform)\n",
    "# print(image_tensors)\n",
    "\n",
    "# # Now you can create a TensorDataset and DataLoader\n",
    "# # from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# dataset = TensorDataset(image_tensors, label_tensors)\n",
    "# loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319338b7",
   "metadata": {},
   "source": [
    "### Implement Lazy Loading for Efficient Memory Usage\n",
    "\n",
    "Use PyTorch's `Dataset` class to load images on-the-fly during training or evaluation, reducing memory usage. This approach avoids loading all images into memory at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "class LazyDataset(Dataset):\n",
    "    def __init__(self, data_list, transform):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data_list[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Example usage\n",
    "lazy_dataset = LazyDataset(dataset_list, transform)\n",
    "# loader = DataLoader(lazy_dataset, batch_size=16, shuffle=True) for testing only\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "# for images, labels in loader:\n",
    "#     print(f\"Batch size: {images.size(0)}, Image shape: {images.shape}, Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf53d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Train/test split and DataLoader creation\n",
    "train_ratio = 0.8\n",
    "# the test ratio will be automatically 0.2\n",
    "\n",
    "# Calculate the sizes for training and testing sets\n",
    "total_size = len(lazy_dataset)\n",
    "train_size = int(total_size * train_ratio)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(lazy_dataset, [train_size, test_size])\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) #imagine it as a pointer to the dataset and not the whole data\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)    \n",
    "\n",
    "# Example usage just to check\n",
    "# for images, labels in train_loader:\n",
    "#     print(f\"Training batch - Images: {images.shape}, Labels: {labels}\")\n",
    "\n",
    "# for images, labels in test_loader:\n",
    "#     print(f\"Testing batch - Images: {images.shape}, Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc585a3a",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Images\n",
    "Display a batch of images from the DataLoader to verify preprocessing and data augmentation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d6e8a",
   "metadata": {},
   "source": [
    "## Training With a simple CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a82178",
   "metadata": {},
   "source": [
    "### Define the CNN Model\n",
    "Build a basic convolutional neural network (CNN) architecture for image classification using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)  ## only 2 outputs in here since it's between real and fake \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1793a",
   "metadata": {},
   "source": [
    "### Training Loop and Visualization\n",
    "Run the training loop and visualize loss and AUC metrics for each epoch and batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea44b7",
   "metadata": {},
   "source": [
    "#### Training for Multiple Epochs\n",
    "Iterate over the dataset for several epochs to optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "# epoch_aucs = []\n",
    "# epoch_losses = []\n",
    "# for epoch in range(2):\n",
    "#     running_loss = 0.0\n",
    "#     correct_train = 0\n",
    "#     total_train = 0\n",
    "#     all_scores = []\n",
    "#     all_labels = []\n",
    "#     epoch_loss_sum = 0.0\n",
    "#     for i, data in enumerate(train_loader, 0):\n",
    "#         inputs, labels = data\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         _, pred_cls = torch.max(outputs, 1)\n",
    "#         correct_train += (pred_cls == labels).sum().item()\n",
    "#         total_train += labels.size(0)\n",
    "#         all_scores.append(outputs[:, 1].detach().cpu())\n",
    "#         all_labels.append(labels.detach().cpu())\n",
    "#         epoch_loss_sum += loss.item()\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 200 == 199:\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "#             running_loss = 0.0\n",
    "#     accuracy = 100 * correct_train / total_train\n",
    "#     all_scores = torch.cat(all_scores)\n",
    "#     all_labels = torch.cat(all_labels)\n",
    "#     auc = roc_auc_score(all_labels.numpy(), all_scores.numpy())\n",
    "#     epoch_aucs.append(auc)\n",
    "#     epoch_losses.append(epoch_loss_sum / len(train_loader))\n",
    "#     print(f'Epoch {epoch + 1} - Accuracy: {accuracy:.2f}%, AUC: {auc:.4f}, Loss: {epoch_loss_sum:.4f}')\n",
    "# print('Finished Training')\n",
    "# torch.save(net.state_dict(), \"fake_image_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be896440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot Epoch Loss and AUC\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epoch_losses, marker='o')\n",
    "# plt.title('Loss per Epoch')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epoch_aucs, marker='o', color='green')\n",
    "# plt.title('AUC per Epoch')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('AUC')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f04b9",
   "metadata": {},
   "source": [
    "#### Batch-Level CNN Training\n",
    "Monitor and log loss, accuracy, and AUC for every batch during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a80601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "cnn_losses = []\n",
    "cnn_accuracies = []\n",
    "cnn_auc_scores = []\n",
    "log_steps = 50  # Every 200 batches\n",
    "epochs_count = 1 # number of epoches\n",
    "\n",
    "for epoch in range(epochs_count):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad() # zeros the gradient for the next batch\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # predictions and accuracy\n",
    "        _, pred_cls = torch.max(outputs, 1) # get the element closest to 1 pred_cls = [1,0,1,0,0,1] .. basically a tensor of 16 predictioons of the class 0 : fake 1 : real\n",
    "        correct_train += (pred_cls == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs[:, 1].detach().cpu())  \n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # Add running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Every 200 batches we save the loss / accuracy / ACU\n",
    "        if i % log_steps == log_steps - 1:\n",
    "            avg_loss = running_loss / log_steps\n",
    "            cnn_losses.append(avg_loss)  # Save instead of per-batch loss\n",
    "            current_accuracy = 100 * correct_train / total_train\n",
    "            cnn_accuracies.append(current_accuracy)\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / log_steps:.3f}, accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            # Save stats every 200 batches\n",
    "            cnn_auc_scores.append(partial_auc)\n",
    "\n",
    "            # Reset for next 200 batches\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "    # Epoch-level stats\n",
    "    print(f'Epoch {epoch + 1} done.\\n')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), \"fake_image_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fc0a2",
   "metadata": {},
   "source": [
    "### Training with a mobilenet_v2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe707a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load MobileNetV2 with pretrained weights\n",
    "mobilenet = models.mobilenet_v2(weights=None.DEFAULT)\n",
    "\n",
    "# Replace final layer for binary classification (1 output)\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 1)\n",
    "\n",
    "# Send to device\n",
    "mobilenet = mobilenet.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "mobilenet.train()\n",
    "\n",
    "\n",
    "mobilNet_losses = []\n",
    "mobilNet_accuracies = []\n",
    "mobilNet_auc_scores = []\n",
    "log_steps = 50  # Every 200 batches\n",
    "epochs_count = 1 # number of epoches\n",
    "\n",
    "for epoch in range(epochs_count):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # Shape: [batch_size, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mobilenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # predictions and accuracy\n",
    "        pred_cls = (torch.sigmoid(outputs) > 0.5).float() ## Applies the sigmoid activation to raw like [[3.2], [-1.1], [0.0], [2.4], ...] to true or false preditions .float() converts them to 1 or 0 \n",
    "        correct_train += (pred_cls == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs.detach().cpu().squeeze())  \n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        # Add running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Every 200 batches we save the loss / accuracy / AUC\n",
    "        if i % log_steps == log_steps - 1:\n",
    "            avg_loss = running_loss / log_steps\n",
    "            mobilNet_losses.append(avg_loss)\n",
    "            current_accuracy = 100 * correct_train / total_train\n",
    "            mobilNet_accuracies.append(current_accuracy)\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f}, accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            mobilNet_auc_scores.append(partial_auc)\n",
    "\n",
    "            # Reset stats\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "    print(f'Epoch {epoch + 1} done.\\n')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(mobilenet.state_dict(), \"fake_image_model_mobilenet.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714ced6",
   "metadata": {},
   "source": [
    "### Visualization of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26309e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps = range(len(cnn_losses))\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# === CNN Model ===\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(steps, cnn_losses, label=\"CNN Loss\")\n",
    "plt.title(\"CNN Training Loss\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(steps, cnn_accuracies, label=\"CNN Accuracy\")\n",
    "plt.title(\"CNN Training Accuracy\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(steps, cnn_aucs, label=\"CNN AUC\")\n",
    "plt.title(\"CNN AUC\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "# === MobileNet ===\n",
    "steps = range(len(mobilenet_losses))\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(steps, mobilenet_losses, label=\"MobileNet Loss\", color='orange')\n",
    "plt.title(\"MobileNetV2 Training Loss\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(steps, mobilenet_accuracies, label=\"MobileNet Accuracy\", color='orange')\n",
    "plt.title(\"MobileNetV2 Accuracy\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(steps, mobilenet_aucs, label=\"MobileNet AUC\", color='orange')\n",
    "plt.title(\"MobileNetV2 AUC\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2e0b3",
   "metadata": {},
   "source": [
    "### Testing and Visualization\n",
    "Evaluate the trained model on the test set and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea910c",
   "metadata": {},
   "source": [
    "#### Test Metrics per Epoch\n",
    "Track and visualize loss and AUC for each test epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing loop\n",
    "# test_aucs = []  # Initialize list to store AUC values\n",
    "# test_losses = []  # Initialize list to store loss values\n",
    "\n",
    "# with torch.no_grad():  # Disable gradient computation for testing\n",
    "#     running_loss = 0.0\n",
    "#     correct_test = 0\n",
    "#     total_test = 0\n",
    "#     all_scores = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     for i, data in enumerate(test_loader, 0):\n",
    "#         inputs, labels = data\n",
    "#         outputs = net(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         _, pred_cls = torch.max(outputs, 1)\n",
    "#         correct_test += (pred_cls == labels).sum().item()\n",
    "#         total_test += labels.size(0)\n",
    "#         all_scores.append(outputs[:, 1].detach().cpu())  # Assuming binary classification\n",
    "#         all_labels.append(labels.detach().cpu())\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "    \n",
    "#     accuracy = 100 * correct_test / total_test\n",
    "#     all_scores = torch.cat(all_scores)\n",
    "#     all_labels = torch.cat(all_labels)\n",
    "#     auc = roc_auc_score(all_labels.numpy(), all_scores.numpy())\n",
    "#     test_aucs.append(auc)  # Save AUC for testing\n",
    "#     test_losses.append(running_loss)  # Save total loss for testing\n",
    "#     print(f'Test - Accuracy: {accuracy:.2f}%, AUC: {auc:.4f}, Loss: {running_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Loss and AUC\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(range(1, len(test_losses) + 1), test_losses, marker='o', label='Loss')\n",
    "# plt.title('Test Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(range(1, len(test_aucs) + 1), test_aucs, marker='o', label='AUC')\n",
    "# plt.title('Test AUC')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('AUC')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83026b",
   "metadata": {},
   "source": [
    "#### Test Metrics per mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f29d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_steps = 5  # or any number \n",
    "\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_auc_scores = []\n",
    "\n",
    "running_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, pred_cls = torch.max(outputs, 1)\n",
    "        correct_test += (pred_cls == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs[:, 1].detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Every log_steps batches, calculate and save metrics\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            current_accuracy = 100 * correct_test / total_test\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            avg_loss = running_loss / log_steps\n",
    "\n",
    "            test_losses.append(avg_loss)\n",
    "            test_accuracies.append(current_accuracy)\n",
    "            test_auc_scores.append(partial_auc)\n",
    "\n",
    "            # Print statistics\n",
    "            print(f'Test batches [{i+1-log_steps+1}â€“{i+1}]: Loss: {avg_loss:.4f}, Accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            # Reset for next interval\n",
    "            running_loss = 0.0\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "print('Finished Testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f5e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Log Interval')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Log Interval')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(test_auc_scores, label='Test AUC')\n",
    "plt.xlabel('Log Interval')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afdc64",
   "metadata": {},
   "source": [
    "### Interface for single image testing \n",
    "using gradio for a GUI to test the outputs of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "# Load model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"fake_image_model.pth\", map_location=\"cpu\"))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "\n",
    "# Define transform and predict function\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Optional but often helpful\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "def predict(img):\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = net(img_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[0]  # Get first sample's output\n",
    "\n",
    "    fake_prob = probabilities[1].item()  # Assuming class index 1 = \"Fake\"\n",
    "    real_prob = probabilities[0].item()\n",
    "    return {\"Fake\": fake_prob, \"Real\": real_prob}\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"Fake Image Detector\",\n",
    "    description=\"Upload an image to detect if it's fake or real.\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
