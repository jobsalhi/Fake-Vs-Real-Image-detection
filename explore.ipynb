{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6756684b",
   "metadata": {},
   "source": [
    "# Deepfake Image Classification with PyTorch\n",
    "\n",
    "This notebook demonstrates a full workflow for classifying deepfake images using a convolutional neural network (CNN) in PyTorch. The steps include data exploration, preprocessing, model building, training, and evaluation, with visualizations and clear explanations throughout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7aa984",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "\n",
    "In this section, we import all the necessary libraries used throughout the notebook. These include tools for data handling, image processing, deep learning (PyTorch), evaluation metrics, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ab854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Data handling and image processing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch and TorchVision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Evaluation and model metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Interface\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dbc61f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd429b",
   "metadata": {},
   "source": [
    "\n",
    "### Visualize a Sample Image\n",
    "Display a sample image from the dataset to verify image loading and format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display a sample image to verify loading\n",
    "def show_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_image(\"FF++/Fake/000_003/001_0.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5de5ff",
   "metadata": {},
   "source": [
    "### Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_dataset(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    for category in root.iterdir():\n",
    "        print(f\"[{category.name}]\")\n",
    "        for person_folder in category.iterdir():\n",
    "            print(f\"  - {person_folder.name}: {len(list(person_folder.glob('*.tiff')))} images\")\n",
    "explore_dataset(\"FF++\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09f4396",
   "metadata": {},
   "source": [
    "### Prepare the Dataset List\n",
    "\n",
    "We create a list of image file paths along with their corresponding labels to be used for training and evaluation.\n",
    "The key idea is to split the dataset **by subject**, ensuring that each person appears only in the **training** or **testing** set, but not both. This avoids data leakage and ensures a more realistic evaluation of model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ddd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_root = Path(\"FF++/Real\")\n",
    "fake_root = Path(\"FF++/Fake\")\n",
    "#preparing the real folder\n",
    "#get folder names for real folder\n",
    "real_folders = sorted([f.name for f in real_root.iterdir() if f.is_dir()])\n",
    "train_ids, test_ids = train_test_split(real_folders, test_size=0.2, random_state=42) #split the folders for testing and training\n",
    "\n",
    "train_real_images = []\n",
    "test_real_images = []\n",
    "#prepare the tuple of (imgURL,label)\n",
    "for folder in train_ids:\n",
    "    for img in (real_root / folder).glob(\"*.tiff\"):\n",
    "        train_real_images.append((str(img), 0))\n",
    "\n",
    "for folder in test_ids:\n",
    "    for img in (real_root / folder).glob(\"*.tiff\"):\n",
    "        test_real_images.append((str(img), 0))\n",
    "\n",
    "#preparing the fake folder\n",
    "train_fake_images = []\n",
    "test_fake_images = []\n",
    "\n",
    "for fake_folder in fake_root.iterdir():\n",
    "    if not fake_folder.is_dir():\n",
    "        continue\n",
    "\n",
    "    #for example 001_870 becomes 001 to match the real folder\n",
    "    real_id = fake_folder.name.split('_')[0]\n",
    "    \n",
    "    # use the previous list of ids for testing and training to prepare or fake images to have the same split and content of persons\n",
    "    if real_id in train_ids:\n",
    "        for img in fake_folder.glob(\"*.tiff\"):\n",
    "            train_fake_images.append((str(img), 1))\n",
    "    elif real_id in test_ids:\n",
    "        for img in fake_folder.glob(\"*.tiff\"):\n",
    "            test_fake_images.append((str(img), 1))\n",
    "\n",
    "train_data = train_real_images + train_fake_images\n",
    "test_data = test_real_images + test_fake_images\n",
    "\n",
    "print(f'train data : {train_data[:5]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0682f06",
   "metadata": {},
   "source": [
    "note : we could've used the `load_dataset` from `datasets` but each dataset would be {'image': {'path': '/path/to/image.jpg', 'bytes': None}, 'label': 1} which is very long "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319338b7",
   "metadata": {},
   "source": [
    "### Implement Lazy Loading for Efficient Memory Usage\n",
    "\n",
    "Use PyTorch's `Dataset` class to load images on-the-fly during training or evaluation, reducing memory usage. This approach avoids loading all images into memory at once.\n",
    "basic approach of loading all in the memory will consume huge resources and slow the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "class LazyDataset(Dataset):\n",
    "    def __init__(self, data_list, transform):\n",
    "        self.data_list = data_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data_list[idx]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf53d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = LazyDataset(train_data, transform)\n",
    "# print(train_dataset)\n",
    "test_dataset = LazyDataset(test_data, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True) #turned to true because the ways the data is loaded it needs to be shuffled\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc585a3a",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Images\n",
    "Display a batch of images from the DataLoader to verify preprocessing and data augmentation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d6e8a",
   "metadata": {},
   "source": [
    "## Training: Simple CNN Model vs. MobileNetV2 (No weights)\n",
    "\n",
    "We compare two convolutional neural network architectures trained from scratch on the same dataset:\n",
    "\n",
    "- A custom-built simple CNN model.\n",
    "- A MobileNetV2 model initialized without pretrained weights.\n",
    "\n",
    "Both models are trained for **one epoch only** in order to:\n",
    "- Benchmark their **initial accuracy** on the test set.\n",
    "- Measure and compare their **training time**.\n",
    "\n",
    "This quick comparison provides insights into their relative performance and computational cost in a minimal training scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a82178",
   "metadata": {},
   "source": [
    "### Define the CNN Model\n",
    "Build a basic convolutional neural network (CNN) architecture for image classification using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)  ## only 2 outputs in here since it's between real and fake \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1729fc",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer\n",
    "\n",
    "For this project, I chose the following setup for training the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d94d9ac",
   "metadata": {},
   "source": [
    "I used CrossEntropyLoss because this project is a classification task \n",
    "\n",
    "The Adam optimizer was selected for its adaptive learning rate capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f04b9",
   "metadata": {},
   "source": [
    "#### Batch-Level CNN Training\n",
    "Monitor and log loss, accuracy, and AUC for every mini-batch set by log-steps during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a80601",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "\n",
    "cnn_losses = []\n",
    "cnn_accuracies = []\n",
    "cnn_auc_scores = []\n",
    "log_steps = 50  #every 16*50 set we log the auc loss and the accuracy\n",
    "epochs_count = 1\n",
    "\n",
    "for epoch in range(epochs_count):\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, pred_cls = torch.max(outputs, 1)\n",
    "        correct_train += (pred_cls == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs[:, 1].detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % log_steps == log_steps - 1:\n",
    "            avg_loss = running_loss / log_steps\n",
    "            cnn_losses.append(avg_loss)\n",
    "            current_accuracy = 100 * correct_train / total_train\n",
    "            cnn_accuracies.append(current_accuracy)\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f}, accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "            cnn_auc_scores.append(partial_auc)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "    print(f'Epoch {epoch + 1} done.\\n')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(net.state_dict(), \"fake_image_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fc0a2",
   "metadata": {},
   "source": [
    "### Training with a mobilenet_v2 model\n",
    "I chose MobileNetV2 as a baseline for comparison because it is a lightweight convolutional neural network architecture that is specifically designed for efficiency on devices with limited computational resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe707a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Load MobileNetV2 with no pretrained weights\n",
    "mobilenet = models.mobilenet_v2(weights=None)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenet.parameters(), lr=1e-4)\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 1)\n",
    "\n",
    "mobilenet = mobilenet.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "mobilenet.train()\n",
    "\n",
    "mobilNet_losses = []\n",
    "mobilNet_accuracies = []\n",
    "mobilNet_auc_scores = []\n",
    "log_steps = 50  # Every 50 batches\n",
    "epochs_count = 1 # number of epoches\n",
    "\n",
    "for epoch in range(epochs_count):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.float().unsqueeze(1).to(device)  # Shape: [batch_size, 1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mobilenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred_cls = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        correct_train += (pred_cls == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs.detach().cpu().squeeze())  \n",
    "        all_labels.append(labels.detach().cpu())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % log_steps == log_steps - 1:\n",
    "            avg_loss = running_loss / log_steps\n",
    "            mobilNet_losses.append(avg_loss)\n",
    "            current_accuracy = 100 * correct_train / total_train\n",
    "            mobilNet_accuracies.append(current_accuracy)\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {avg_loss:.3f}, accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            mobilNet_auc_scores.append(partial_auc)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "    print(f'Epoch {epoch + 1} done.\\n')\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(mobilenet.state_dict(), \"fake_image_model_mobilenetCPU.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714ced6",
   "metadata": {},
   "source": [
    "### Visualization of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26309e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "steps = range(len(cnn_losses))\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "#  CNN Model \n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(steps, cnn_losses, label=\"CNN Loss\")\n",
    "plt.title(\"CNN Training Loss\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(steps, cnn_accuracies, label=\"CNN Accuracy\")\n",
    "plt.title(\"CNN Training Accuracy\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(steps, cnn_auc_scores, label=\"CNN AUC\")\n",
    "plt.title(\"CNN AUC\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "#  MobileNet \n",
    "steps = range(len(mobilNet_losses))\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(steps, mobilNet_losses, label=\"MobileNet Loss\", color='orange')\n",
    "plt.title(\"MobileNetV2 Training Loss\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(steps, mobilNet_accuracies, label=\"MobileNet Accuracy\", color='orange')\n",
    "plt.title(\"MobileNetV2 Accuracy\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(steps, mobilNet_auc_scores, label=\"MobileNet AUC\", color='orange')\n",
    "plt.title(\"MobileNetV2 AUC\")\n",
    "plt.xlabel(\"Log step\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2e0b3",
   "metadata": {},
   "source": [
    "### Testing and Visualization\n",
    "Evaluate the trained model on the test set and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a2e5e",
   "metadata": {},
   "source": [
    "#### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f29d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc , ConfusionMatrixDisplay\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load model\n",
    "device = torch.device(\"cpu\")\n",
    "net.load_state_dict(torch.load(\"fake_image_model.pth\", map_location=device))\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Logging and tracking\n",
    "log_steps = 5\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "test_auc_scores = []\n",
    "\n",
    "running_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "all_preds = []  # predicted class labels\n",
    "all_true = []   # true labels\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, pred_cls = torch.max(outputs, 1)\n",
    "\n",
    "        correct_test += (pred_cls == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "        all_scores.append(outputs[:, 1].detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "        all_preds.extend(pred_cls.cpu().numpy())\n",
    "        all_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            avg_loss = running_loss / log_steps\n",
    "            current_accuracy = 100 * correct_test / total_test\n",
    "            partial_scores = torch.cat(all_scores)\n",
    "            partial_labels = torch.cat(all_labels)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            test_losses.append(avg_loss)\n",
    "            test_accuracies.append(current_accuracy)\n",
    "            test_auc_scores.append(partial_auc)\n",
    "\n",
    "            print(f'Test batches [{i + 1 - log_steps + 1}–{i + 1}]: '\n",
    "                  f'Loss: {avg_loss:.4f}, Accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            running_loss = 0.0\n",
    "            correct_test = 0\n",
    "            total_test = 0\n",
    "            all_scores = []\n",
    "            all_labels = []\n",
    "\n",
    "print('Finished Testing CNN')\n",
    "cm = confusion_matrix(all_true, all_preds)\n",
    "# confusion matrix with Plotly\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Real\", \"Fake\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d70ed8",
   "metadata": {},
   "source": [
    "#### Mobilenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc , ConfusionMatrixDisplay\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --- MobileNet Testing ---\n",
    "device_mobilenet = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mobilenet = models.mobilenet_v2(weights=None)\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 1)\n",
    "\n",
    "mobilenet.load_state_dict(torch.load(\"fake_image_model_mobilenetCPU.pth\", map_location=device_mobilenet))\n",
    "mobilenet = mobilenet.to(device_mobilenet)\n",
    "mobilenet.eval()\n",
    "\n",
    "criterion_mobilenet = nn.BCEWithLogitsLoss()\n",
    "\n",
    "log_steps_mobilenet = 5\n",
    "test_losses_mobilenet = []\n",
    "test_accuracies_mobilenet = []\n",
    "test_auc_scores_mobilenet = []\n",
    "\n",
    "running_loss_mobilenet = 0.0\n",
    "correct_test_mobilenet = 0\n",
    "total_test_mobilenet = 0\n",
    "all_scores_mobilenet = []\n",
    "all_labels_mobilenet = []\n",
    "\n",
    "all_preds_mobilenet = []  # predicted class labels\n",
    "all_true_mobilenet = []   # true labels\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device_mobilenet)\n",
    "        labels = labels.float().unsqueeze(1).to(device_mobilenet)\n",
    "\n",
    "        outputs = mobilenet(inputs)\n",
    "        loss = criterion_mobilenet(outputs, labels)\n",
    "\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        pred_cls = (probs > 0.5).float()\n",
    "\n",
    "        correct_test_mobilenet += (pred_cls == labels).sum().item()\n",
    "        total_test_mobilenet += labels.size(0)\n",
    "\n",
    "        all_scores_mobilenet.append(outputs.detach().cpu().squeeze())\n",
    "        all_labels_mobilenet.append(labels.detach().cpu())\n",
    "        all_preds_mobilenet.extend(pred_cls.cpu().numpy())\n",
    "        all_true_mobilenet.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "        running_loss_mobilenet += loss.item()\n",
    "\n",
    "        if (i + 1) % log_steps_mobilenet == 0:\n",
    "            avg_loss = running_loss_mobilenet / log_steps_mobilenet\n",
    "            current_accuracy = 100 * correct_test_mobilenet / total_test_mobilenet\n",
    "            partial_scores = torch.cat(all_scores_mobilenet)\n",
    "            partial_labels = torch.cat(all_labels_mobilenet)\n",
    "            partial_auc = roc_auc_score(partial_labels.numpy(), partial_scores.numpy())\n",
    "\n",
    "            test_losses_mobilenet.append(avg_loss)\n",
    "            test_accuracies_mobilenet.append(current_accuracy)\n",
    "            test_auc_scores_mobilenet.append(partial_auc)\n",
    "\n",
    "            print(f'MobileNet Test batches [{i + 1 - log_steps_mobilenet + 1}–{i + 1}]: '\n",
    "                  f'Loss: {avg_loss:.4f}, Accuracy: {current_accuracy:.2f}%, AUC: {partial_auc:.4f}')\n",
    "\n",
    "            running_loss_mobilenet = 0.0\n",
    "            correct_test_mobilenet = 0\n",
    "            total_test_mobilenet = 0\n",
    "            all_scores_mobilenet = []\n",
    "            all_labels_mobilenet = []\n",
    "\n",
    "print('Finished Testing MobileNet')\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_true_mobilenet, all_preds_mobilenet)\n",
    "# confusion matrix with Plotly\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Real\", \"Fake\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf90a1f",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs_mobilenet = range(1, len(test_losses_mobilenet) + 1)\n",
    "epochs_cnn = range(1, len(test_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs_mobilenet, test_losses_mobilenet, label='MobileNet Loss', marker='o')\n",
    "plt.plot(epochs_cnn, test_losses, label='CNN Loss', marker='o')\n",
    "plt.title('Test Loss')\n",
    "plt.xlabel('Log Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs_mobilenet, test_accuracies_mobilenet, label='MobileNet Accuracy', marker='o')\n",
    "plt.plot(epochs_cnn, test_accuracies, label='CNN Accuracy', marker='o')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Log Step')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot AUC\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs_mobilenet, test_auc_scores_mobilenet, label='MobileNet AUC', marker='o')\n",
    "plt.plot(epochs_cnn, test_auc_scores, label='CNN AUC', marker='o')\n",
    "plt.title('Test AUC Score')\n",
    "plt.xlabel('Log Step')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afdc64",
   "metadata": {},
   "source": [
    "### Interface for single image testing \n",
    "using gradio for a GUI to test the outputs of the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(\"fake_image_model.pth\", map_location=\"cpu\"))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "\n",
    "# Define transform and predict function\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Optional but often helpful\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "def predict(img):\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = net(img_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)[0]  # Get first sample's output\n",
    "\n",
    "    fake_prob = probabilities[1].item()  # Assuming class index 1 = \"Fake\"\n",
    "    real_prob = probabilities[0].item()\n",
    "    return {\"Fake\": fake_prob, \"Real\": real_prob}\n",
    "\n",
    "\n",
    "# Gradio Interface\n",
    "demo = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"pil\"),\n",
    "    outputs=gr.Label(num_top_classes=2),\n",
    "    title=\"Fake Image Detector\",\n",
    "    description=\"Upload an image to detect if it's fake or real.\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
